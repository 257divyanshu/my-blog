---
title: Understanding LLMs (The Brains Behind AI)
date: 2025-11-08
description: A beginner-friendly guide to how Large Language Models (LLMs) work. From tokenization to evaluation, and why theyâ€™re the brains behind modern AI.
---

Welcome to my blog ğŸ‘‹

If youâ€™ve ever wondered how ChatGPT seems to â€œunderstandâ€ you, this post is for you.

Behind tools like ChatGPT, Gemini, Claude, and Copilot are Large Language Models (LLMs), the powerful AI systems that can understand and generate human language.

Letâ€™s explore what makes them so capable, and how theyâ€™re evaluated to ensure they work reliably.

---

## ğŸ What Is an LLM?

A **Large Language Model (LLM)** is an AI system trained to **understand and generate human language**.

Youâ€™ve already interacted with many: ChatGPT, Gemini, Claude, Copilot. Theyâ€™re all LLMs.

Think of an LLM as a **â€œstatistical brainâ€** that predicts what word (or token) should come next in a sentence, based on everything itâ€™s seen so far.

```
Input:   "Artificial intelligence is"

Model:   â†’ predicts "changing"
          â†’ then predicts "the"
          â†’ then predicts "world"

Output:  "Artificial intelligence is changing the world."
```

---

## ğŸ§© The â€œLargeâ€ in LLMs

The *â€œlargeâ€* refers to:

* The **amount of data** itâ€™s trained on (hundreds of billions of words)
* The **number of parameters**: Think of parameters as tiny â€œknobsâ€ or â€œdialsâ€ that the model tunes during training to adjust how it understands language patterns.

GPT-4 and Gemini have **hundreds of billions** of parameters!

```
            -------------------------------------
Data  >>>>    billions of sentences, books, web  
            -------------------------------------
                       â†“  â†“  â†“  â†“  â†“
               billions of internal parameters
```

Each parameter adjusts slightly during training to help the model understand relationships between words, meaning, and context.

---

## âš™ï¸ How an LLM Works?

Letâ€™s simplify the pipeline into **3 stages:**

```
-------------------------
  Stage 1: Tokenization    
-------------------------

Input text is broken into smaller units (tokens).

"Hello world!" â†’ ["Hello", " world", "!"]

```

```
-------------------------------------
  Stage 2: Encoding (Understanding)  
-------------------------------------

Each token becomes a vector (a list of numbers that captures meaning).

"Hello" â†’ [0.1, 0.9, -0.3, 0.4, ...]

These vectors go into a neural network (Transformer) that learns relationships.
```

```
----------------------------------
  Stage 3: Decoding (Generation)  
----------------------------------

The model predicts the next token based on previous ones:

Input: "The sky is"
â†’ predicts "blue"
â†’ output: "The sky is blue"
```

Thatâ€™s how every chatbot answer is built, **one token at a time**, extremely fast.

---

## ğŸ§  Why LLMs Are So Capable?

Because theyâ€™ve *seen* almost everything humans have written online and theyâ€™ve learned **patterns of reasoning, style, and structure**.

They donâ€™t â€œthinkâ€ like humans, they â€œguessâ€ extremely well based on context.
Thatâ€™s why they can:

* Write essays, code, and stories
* Answer factual questions
* Translate languages
* Simulate conversation

---

## âš–ï¸ Why Evaluate LLMs?

LLMs are powerful, but theyâ€™re not perfect.

They can:
* Make up facts (hallucinate)
* Be biased
* Miss key context
* Give inconsistent answers

So, just like humans are tested in exams, **LLMs must be tested** before being trusted. Thatâ€™s where *evaluation techniques* come in.

---

## ğŸ” Evaluating LLMs Is Hard

Unlike a simple math test where answers are either right or wrong,
LLMs produce **subjective, creative, or contextual** outputs.

Example:

```
Prompt: "Write a paragraph about the moon."
```

Output A:

> The moon is Earth's only natural satellite, influencing tides...

Output B:

> A glowing companion of the night sky, the moon inspires poets...

Which one is â€œbetterâ€?
Thereâ€™s no single correct answer. Thatâ€™s why evaluation is hard.

So researchers use multiple approaches:

* Human judgments (slow, expensive)
* Automated metrics (fast, limited)
* Hybrid or model-based evaluations (modern standard)

---

## ğŸ§­ The Types of Evaluation

We can group LLM evaluation into **three main families**:

```
-----------------------------
  1ï¸âƒ£ Human Evaluation    
     - Humans rate outputs   
     - Very reliable         
     - Slow & costly         
-----------------------------

-----------------------------
  2ï¸âƒ£ Automated Metrics     
     - Scores via formulas   
     - Fast & reproducible    
     - May miss nuance       
-----------------------------

--------------------------------
  3ï¸âƒ£ Model-based Evaluation 
     - LLM judges another LLM
     - Scalable & modern       
     - Needs careful prompt   
--------------------------------

```


---

## âœï¸ Summary:

> Large Language Models are statistical engines trained on vast text data to predict the next word.

> They donâ€™t â€œthinkâ€, they pattern-match extremely well.

> Their creativity and inconsistency make evaluation challenging, leading to sophisticated testing techniques.

**Key takeaway diagram:**

```
Prompt â†’ Tokenize â†’ Encode â†’ Generate â†’ Evaluate â†’ Improve
```

---

Thanks for reading till the end! ğŸ™

I hope this post helped you get a clearer picture of how LLMs actually work behind the scenes.

Weâ€™re just getting started! In the upcoming posts, weâ€™ll explore how these models are judged and improved.

**See you in the next post ğŸ‘‹**