---
title: Understanding Large Language Models (LLMs) â€” The Brains Behind AI
date: 2025-11-08
description: A beginner-friendly guide to how Large Language Models (LLMs) work â€” from tokenization to evaluation â€” and why theyâ€™re the brains behind modern AI.
---

Welcome to my blog ğŸ‘‹

If youâ€™ve ever wondered how ChatGPT seems to â€œunderstandâ€ you â€” this post is for you.

Behind tools like ChatGPT, Gemini, Claude, and Copilot are Large Language Models (LLMs) â€” powerful AI systems that can understand and generate human language.
Letâ€™s explore what makes them so capable, and how theyâ€™re evaluated to ensure they work reliably.

---

## ğŸ What Is an LLM?

A **Large Language Model (LLM)** is an AI system trained to **understand and generate human language**.
Youâ€™ve already interacted with many â€” ChatGPT, Gemini, Claude, Copilot â€” theyâ€™re all LLMs.

Think of an LLM as a **â€œstatistical brainâ€** that predicts what word (or token) should come next in a sentence, based on everything itâ€™s seen so far.

```
Input:   "Artificial intelligence is"
Model:   â†’ predicts "changing"
          â†’ then predicts "the"
          â†’ then predicts "world"
Output:  "Artificial intelligence is changing the world."
```

---

## ğŸ§© The â€œLargeâ€ in LLMs

The *â€œlargeâ€* refers to:

* The **amount of data** itâ€™s trained on (hundreds of billions of words)
* The **number of parameters** â€” think of parameters as tiny â€œknobsâ€ or â€œdialsâ€ that the model tunes during training to adjust how it understands language patterns. GPT-4 and Gemini have **hundreds of billions** of parameters!

```
           +-----------------------------------+
Data  ---> | billions of sentences, books, web |
           +-----------------------------------+
             â†“  â†“  â†“  â†“  â†“
       billions of internal parameters
```

Each parameter adjusts slightly during training to help the model understand relationships between words, meaning, and context.

---

## âš™ï¸ How an LLM Works?

Letâ€™s simplify the pipeline into **3 stages:**

```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     Stage 1: Tokenization     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Input text is broken into smaller units (tokens).

"Hello world!" â†’ ["Hello", " world", "!"]

```

```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     Stage 2: Encoding (Understanding)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Each token becomes a vector â€” a list of numbers that captures meaning.

"Hello" â†’ [0.1, 0.9, -0.3, 0.4, ...]

These vectors go into a neural network (Transformer) that learns relationships.
```

```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     Stage 3: Decoding (Generation)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
The model predicts the next token based on previous ones:

Input: "The sky is"
â†’ predicts "blue"
â†’ output: "The sky is blue"
```

Thatâ€™s how every chatbot answer is built â€” **one token at a time**, extremely fast.

---

## ğŸ§  Why LLMs Are So Capable?

Because theyâ€™ve *seen* almost everything humans have written online â€”
and theyâ€™ve learned **patterns of reasoning, style, and structure**.

They donâ€™t â€œthinkâ€ like humans â€” they â€œguessâ€ extremely well based on context.
Thatâ€™s why they can:

* Write essays, code, and stories
* Answer factual questions
* Translate languages
* Simulate conversation

---

## âš–ï¸ Why Evaluate LLMs?

LLMs are powerful â€” but theyâ€™re not perfect.
They can:

* Make up facts (hallucinate)
* Be biased
* Miss key context
* Give inconsistent answers

So, just like humans are tested in exams, **LLMs must be tested** before being trusted â€” thatâ€™s where *evaluation techniques* come in.

---

## ğŸ” Evaluating LLMs Is Hard

Unlike a simple math test where answers are either right or wrong,
LLMs produce **subjective, creative, or contextual** outputs.

Example:

```
Prompt: "Write a paragraph about the moon."
```

Output A:

> The moon is Earth's only natural satellite, influencing tides...

Output B:

> A glowing companion of the night sky, the moon inspires poets...

Which one is â€œbetterâ€?
Thereâ€™s no single correct answer â€” thatâ€™s why evaluation is hard.

So researchers use multiple approaches:

* Human judgments (slow, expensive)
* Automated metrics (fast, limited)
* Hybrid or model-based evaluations (modern standard)

---

## ğŸ§­ The Types of Evaluation

We can group LLM evaluation into **three main families**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1ï¸âƒ£ Human Evaluation      
â”‚     - Humans rate outputs   
â”‚     - Very reliable         
â”‚     - Slow & costly         
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2ï¸âƒ£ Automated Metrics     
â”‚     - Scores via formulas   
â”‚     - Fast & reproducible    
â”‚     - May miss nuance       
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3ï¸âƒ£ Model-based Evaluation 
â”‚     - LLM judges another LLM
â”‚     - Scalable & modern       
â”‚     - Needs careful prompt   
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


---

## âœï¸ Summary:

> Large Language Models are statistical engines trained on vast text data to predict the next word.
> They donâ€™t â€œthinkâ€ â€” they pattern-match extremely well.
> Their creativity and inconsistency make evaluation challenging, leading to sophisticated testing techniques.

**Key takeaway diagram:**

```
Prompt â†’ Tokenize â†’ Encode â†’ Generate â†’ Evaluate â†’ Improve
```

---

Thanks for reading till the end! ğŸ™

I hope this post helped you get a clearer picture of how LLMs actually work behind the scenes.
Weâ€™re just getting started â€” in the upcoming posts, weâ€™ll explore how these models are judged and improved.

**See you in the next post ğŸ‘‹**